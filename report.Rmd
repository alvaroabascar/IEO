# Re-analysis of the microarray data published by Murat, A. et al. (2008) "Stem Cell–Related “Self-Renewal” Signature and High Epidermal Growth Factor Receptor Expression Associated With Resistance to Concomitant Chemoradiotherapy in Glioblastoma"

### Álvaro Abella Bascarán (alvaro.abella01@estudiant.upf.edu)
### Eloi Casals (eloi.casals01@estudiant.upf.edu)
### Samuel Miravet Verde (samuel.miravet01@estudiant.upf.edu)

## Introduction

Glioblastoma multiforme is the most presented and aggressive brain tumor in humans, involving glial cells, with an incidence of 2–3 cases per 100,000 person life-years in Europe and North America ([Fonnet E. Bleeker, _et al_ (2012)](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3337398/)).

Treatment can involve chemotherapy, radiation and surgery. Median survival with standard-of-care radiation and chemotherapy with the alkylating agent temozolomide is 15 months([Johnson, Derek R. _et al_ (2011)](http://link.springer.com/article/10.1007%2Fs11060-011-0749-4)) while the median survival without treatment is 4 and a half months. Regretfully glioblastomas are notorious for resistance to therapy, which has been attributed to DNA-repair proficiency, a multitude of deregulated molecular pathways, and, more recently, to the particular biologic behavior of tumor stem-like cells. Here, based on the reference work of [Murat, A. _et al_ (2008)](http://www.ncbi.nlm.nih.gov/pubmed/18565887), we aimed to identify the molecular profiles specific for treatment resistance to the current standard of care of concomitant chemoradiotherapy with temozolomide.

To achieve our goal, we take from the reference study a set of gene expression profiles of 80 glioblastomas of patients treated whithin clinical trials of concomitant and adjuvant temozolomide to radiotherapy (n=52) and patients treated with only radioterapy (n=28). In addition, 4 control patients were added to the study.


This document should be processed from R and you need to install the packages
[knitr](http://cran.r-project.org/web/packages/knitr/index.html) and
[markdown](http://cran.r-project.org/web/packages/markdown/index.html). Once
they are installed, you have to type the following instructions that generate
a HTML document that you can open with a web browser:

```
library(knitr)     ## required for "knitting" from Rmd to md
library(markdown)  ## required for processing from md to HTML
knit("projectTemplate.Rmd", "projectTemplate.md")  ## process Rmd to md
markdownToHTML("projectTemplate.md", "projectTemplate.html") ## process md to HTML
browseURL("projectTemplate.html") ## open the resulting HTML file from R
```

## Data
The microarray data used during the research of [Murat, A. _et al_ (2008)](http://www.ncbi.nlm.nih.gov/pubmed/18565887) can be found at the [Gene Expression Omnibus](http://www.ncbi.nlm.nih.gov/geo/), with the accession number [GSE7696](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE7696). In order to proceed with this analysis, the file [GSE7696_RAW.tar](http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE7696&format=file) must be uncompressed under the directory 'data/raw/' and the file [GSE7696_series_matrix.txt.gz](ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE7nnn/GSE7696/matrix/GSE7696_series_matrix.txt.gz) must be placed inside 'data/'.

## Subsampling

The original data contained 84 samples, of which 4 are controls, 28 correspond to patients treated with radiotherapy, and 52 to patients treated with both TMZ and radiotherapy. In order to have a more manageable analysis we decided to proceed, by now, with only 21 samples. The following script was used to do a subsampling keeping the original proportions among controls, TMZ/radiotherapy and radiotherapy samples.

We need GEOquery to retrieve the assay data and affy to retrieve the expression data.
```{r libraries, message=FALSE}
library(affy)
library(GEOquery)
```

This is a simple way to cache the full eset (all the assay data) in a simple object, to avoid
loading it from the .txt.gz the next time (a costly process)

```{r cache_data}
# Cache the data to avoid having to load it again next time from the .txt
if (file.exists('full_eset.rds')) {
  eset = readRDS('full_eset.rds')
} else {
  eset = getGEO(filename='data/GSE7696_series_matrix.txt.gz')
  saveRDS(eset, 'full_eset.rds')
}
```


We separate the sample names by treatment group, and take enough samples from each group to have a total of 21, keeping the original proportions.

```{r subsampling_step1}
# extract sample names
samples = colnames(eset)

# separate the samples by treatment group
no_treated = samples[eset$characteristics_ch1.5 == "treatment: NA"]
tmz_rt = samples[eset$characteristics_ch1.5 == "treatment: TMZ/radiotherapy"]
rt = samples[eset$characteristics_ch1.5 == "treatment: radiotherapy"]

# take 21 samples, keeping the proportions of the original dataset
no_treated = sample(no_treated, size=1)
tmz_rt = sample(tmz_rt, size=13)
rt = sample(rt, size=7)
```

Join the three arrays of sample names, and turn them into file names. Then read the AffyBatch data from the specified files only. This allows us to retrieve the data much faster, as we are loading only the 21 required samples, and not the whole set of 84 samples.

```{r subsampling_step2}
subsample_names = c(no_treated, tmz_rt, rt)
# turn sample names into filenames
subsample_filenames = paste(subsample_names, '.cel.gz', sep='')

# read only the necessary the expression data
glioData = ReadAffy(celfile.path = "./data/raw", filenames=subsample_filenames)
```

We also filter the original assay data to keep only the data corresponding to the samples we have choosen. We finally save both objects for posterior use. 
```{r subsampling_step3}
subsampled_eset = eset[, subsample_names]

# save the subsampled data for posterior use
saveRDS(subsampled_eset, 'eset.rds')
saveRDS(glioData, 'glioData.rds')

eset = subsampled_eset
```

## Quality assessment and normalization

```{r}
library(affyPLM)
```
We plot, in the first place, the chip images in order to detect artifacts and discard those samples corresponding to malfunctioning chips.
```{r chip_images, out.width="800px", dpi=400}
sampleNames(glioData) = letters[1:21]
# Scanner plot analysis
par(mfrow = c(3, 7), mar = c(1, 1, 3, 1))
image(glioData)
```
From this images we cannot see any obvious artifact, and so far we can consider all of the samples as valids.

<!---

We can further assess the quality of the samples checking the distribution of intensities from each chip. Chips with a distribution which differs significantly from the rest should be taken with caution.
```{r intensity_boxplots}
# Raw intensity boxplot
par(mar = c(4, 5, 0, 1))
boxplot(glioData)
```

```{r density_plots}
# Density plot
par(mar = c(3, 3, 4, 1))
plotDensity.AffyBatch(glioData, lwd=2, col=1:21, lty=1:21)
legend('topright', LETTERS[1:21], col=1:21, lty=1:21, lwd=2, inset=0.1)
```

```{r intensities}
Pset = fitPLM(glioData)
for (i in 1:21) {
  par(mfrow=c(1, 3))
  image(glioData[, i]) # raw intensities for sample A
  image(Pset, type="resids", which=i) # PLM resids for sample A
  image(Pset, type="weights", which=i) # PLM resids for sample A
}
```

```{r NUSE}
# Probe level modeling
NUSE(Pset)

```{r RLE}
# RLE
RLE(Pset)
```

```{r nuse_rle_stats}
nuseDiag = NUSE(Pset, type='stats')
rleDiag = RLE(Pset, type='stats')
```

## Normalization

## Batch identification

The main goal of this step consists in finding if there exist any possible batch effect in our dataset, that is technical sources of variation that have been added to the samples during handling ((Leek et al., 2010)[http://www.nature.com/nrg/journal/v11/n10/full/nrg2825.html#close]). It is important to detect them in order to ensure that the possible future differences between expressions do not come from a non-biological or scientific variables source.

After loading the needed libraries, we start the process retrieving the expression set of study and giving a specific letter to each sample.

```{r message=FALSE}
# library(affy)
# library(Biobase)
# library(GEOquery)

# glioData = readRDS('glioData.rds')
# eset = readRDS('eset.rds')
# sampleNames(glioData) = letters[1:21]
```

Between all the different features our dataset have, the only possible batch source is the experiment date of each sample so this will be our batch grouping variable. To consider it, we have to set a scanDate variable in the correct format:

```{r}
scanDate = protocolData(glioData)$ScanDate
scanDate = gsub(" .*", "", scanDate)
scanDate = as.Date(scanDate, "%m/%d/%y")
```

Once defined that variable, we are already able to group together the samples obtained in the same date:

```{r}
minscan = min(scanDate)
days = scanDate- minscan

sort(days)
```

With those different day groups we can discretize the days numeric variable into desired intervals to finally obtain our surrogate batch indicator variable. In addition, the length of the variable _days_ allows us to define a vector of colors that will be used in the posterior plots.

```{r}
batch_days = data.frame(row.names=sort(unique(days)), batch=c(1:length(unique(days))))

ourcolors = rainbow(length(unique(days)))
```

The differential outcome for our dataset is the survival time as the aim of the study is to define a set of genes expressed differentially between resistant cancer patients and non-resistant. To consider it, we extract the variable from the _eset_ and transform it into a character string.

```{r}
treatment = eset$characteristics_ch1.5

survival_time = eset$characteristics_ch1.7
survival_time = gsub('.*:', '', survival_time)
survival_time = as.character(survival_time)
```

The division of our outcome respect the batch groups can be resumed with the _table_ function:

```{r}
#table(data.frame(Outcome = survival_time, Batch = batch_days))
```

#### HIERARCHICAL CLUSTERING DENDROGRAM

A nice way to see how effectively batch is confounding the outcome of interest consists of doing a hierarchical clustering of the samples indicating the batch to which each of them belongs to. We should start by calculating the distance between every pair of samples using a non-parametric association measure such as (Spearman correlation)[http://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient]:

```{r}
d = as.dist(1 - cor(exprs(eset), method="spearman"))
```

Using _hclust_ we perform the hierarchical clustering which can be easily understood showing it in a (dendrogram)[http://en.wikipedia.org/wiki/Dendrogram].

```{r}
# Hierarchical analysis:

sampleClustering = hclust(d)

# Function to generate the dendrogram:

sampleDendrogram = as.dendrogram(sampleClustering, hang=0.5)
batch = days
names(batch) = sampleNames(eset)
names(survival_time) = sampleNames(eset)
sampleDendrogram = dendrapply(sampleDendrogram, function(x, batch, labels) {
    ## for every node in the dendrogram if it is a leaf node
    if (is.leaf(x)) {
      print(x)
        attr(x, "nodePar") = list(lab.col = as.vector(ourcolors[batch_days[as.character(batch[attr(x, "label")]),]]))
        attr(x, "label") = as.vector(labels[attr(x, "label")])  ## label by survival_time
    }
    x
}, batch, survival_time)

# And the required command to plot it:

plot(sampleDendrogram, main = "Hierarchical clustering of samples")
legend("topright", paste("Batch", sort(unique(batch))), fill = ourcolors)
```

#TODO --> explain the dendrogram!


## Differential expression

## Conclusion

## Session information

```{r}
sessionInfo()
```

--->